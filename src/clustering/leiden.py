"""
Implementation of the Leiden algorithm for community detection.
"""

from collections.abc import Set
from math import exp
from random import choices, shuffle
from typing import TypeVar

import networkx as nx
from networkx import Graph
from typing import Union

from sklearn.metrics import adjusted_mutual_info_score

from .quality_functions import QualityFunction
from .utils import DataKeys as Keys
from .utils import Partition, argmax, freeze, node_total, preprocess_graph

T = TypeVar("T")


def move_nodes_fast(G: Graph, ğ“Ÿ: Partition[T], ğ“—: QualityFunction[T], other_partitions: list[Partition[T]], Î»: float) -> Partition[T]:
    """
    é€šè¿‡å¿«é€Ÿçš„å±€éƒ¨èŠ‚ç‚¹ç§»åŠ¨æ¥æ”¹å–„ç¤¾åŒºåˆ’åˆ†çš„è´¨é‡ï¼ŒåŒæ—¶è€ƒè™‘ä¸å…¶ä»–å¤´çš„äº’ä¿¡æ¯æ­£åˆ™åŒ–ä»¥é¼“åŠ±å¤šæ ·æ€§ã€‚
    
    å‚æ•°
    ----------
    G : Graph
        è¦å¤„ç†çš„å›¾/ç½‘ç»œã€‚
    ğ“Ÿ : Partition[T]
        å½“å‰æ­£åœ¨ä¼˜åŒ–çš„ç¤¾åŒºåˆ’åˆ†ã€‚
    ğ“— : QualityFunction[T]
        è¦ä¼˜åŒ–çš„è´¨é‡å‡½æ•°ã€‚
    other_partitions : list[Partition[T]]
        å…¶ä»–å¤´çš„ç¤¾åŒºåˆ’åˆ†ï¼Œç”¨äºäº’ä¿¡æ¯æ­£åˆ™åŒ–ã€‚
    Î» : float
        äº’ä¿¡æ¯æ­£åˆ™åŒ–çš„æƒé‡ã€‚
    
    è¿”å›
    -------
    Partition[T]
        èŠ‚ç‚¹ç§»åŠ¨åçš„æ›´æ–°åˆ’åˆ†ã€‚
    """
    
    # å°†æ‰€æœ‰èŠ‚ç‚¹éšæœºæ’åˆ—ï¼Œå¼€å§‹è¿›è¡ŒèŠ‚ç‚¹ç§»åŠ¨
    Q = list(G.nodes)
    shuffle(Q)

    # åˆ›å»ºä¸€ä¸ªé›†åˆç”¨äºè®°å½•å·²è®¿é—®çš„èŠ‚ç‚¹
    visited_nodes = set()

    # å¾ªç¯ç›´åˆ°æ‰€æœ‰èŠ‚ç‚¹éƒ½è¢«å¤„ç†
    while True:
        # ä»é˜Ÿåˆ—ä¸­å¼¹å‡ºä¸€ä¸ªèŠ‚ç‚¹vï¼Œå¹¶å°†å…¶æ ‡è®°ä¸ºå·²è®¿é—®
        v = Q.pop(0)
        visited_nodes.add(v)

        # å®šä¹‰è®¡ç®—äº’ä¿¡æ¯æƒ©ç½šçš„å‡½æ•°ï¼Œç›®æ ‡æ˜¯æƒ©ç½šè¿‡äºç›¸ä¼¼çš„ç¤¾åŒºåˆ’åˆ†
        def mutual_info_penalty(target_community):
            penalty = 0
            # éå†å…¶ä»–å¤´çš„ç¤¾åŒºåˆ’åˆ†ï¼Œç´¯åŠ äº’ä¿¡æ¯æƒ©ç½š
            for other_partition in other_partitions:
                penalty += mutual_info(ğ“Ÿ, other_partition)
            return penalty

        # è®¡ç®—vèŠ‚ç‚¹ç§»åŠ¨åˆ°æ¯ä¸ªç›¸é‚»ç¤¾åŒºçš„è´¨é‡æå‡ï¼Œå¹¶ç»“åˆäº’ä¿¡æ¯æƒ©ç½š
        (Câ‚˜, ğ›¥ğ“—, _) = argmax(
            lambda C: ğ“—.delta(ğ“Ÿ, v, C) - Î» * mutual_info_penalty(C),
            [*ğ“Ÿ.adjacent_communities(v), set()]  # é‚»æ¥ç¤¾åŒºå’Œç©ºé›†ä½œä¸ºå€™é€‰ç›®æ ‡
        )

        # å¦‚æœç§»åŠ¨vèŠ‚ç‚¹å¯ä»¥æå‡è´¨é‡ï¼ˆğ›¥ğ“— > 0ï¼‰ï¼Œåˆ™è¿›è¡Œç§»åŠ¨
        if ğ›¥ğ“— > 0:
            ğ“Ÿ.move_node(v, Câ‚˜)  # å°†èŠ‚ç‚¹vç§»åŠ¨åˆ°ç›®æ ‡ç¤¾åŒºCâ‚˜
            
            # æ‰¾å‡ºä¸vç›¸è¿ä½†å°šæœªè®¿é—®çš„èŠ‚ç‚¹ï¼Œå°†å…¶åŠ å…¥é˜Ÿåˆ—è¿›è¡Œå¤„ç†
            N = {u for u in G[v] if u not in Câ‚˜ and u not in visited_nodes}
            Q.extend(N - set(Q))  # ç¡®ä¿æ–°èŠ‚ç‚¹ä¸ä¼šé‡å¤åŠ å…¥é˜Ÿåˆ—

        # å¦‚æœé˜Ÿåˆ—Qä¸ºç©ºï¼Œè¡¨ç¤ºæ‰€æœ‰èŠ‚ç‚¹éƒ½å·²å¤„ç†å®Œæ¯•ï¼Œè¿”å›æœ€ç»ˆçš„ç¤¾åŒºåˆ’åˆ†
        if len(Q) == 0:
            return ğ“Ÿ




def refine_partition(G: Graph, ğ“Ÿ: Partition[T], ğ“—: QualityFunction[T], Î¸: float, Î³: float) -> Partition[T]:
    """é€šè¿‡é‡å¤åˆå¹¶çš„æ–¹å¼ç»†åŒ–æ‰€æœ‰ç¤¾åŒºï¼Œä»å•èŠ‚ç‚¹åˆ’åˆ†å¼€å§‹ã€‚"""
    
    # å°†æ¯ä¸ªèŠ‚ç‚¹åˆ†é…åˆ°å®ƒè‡ªå·±çš„ç¤¾åŒºï¼ˆåˆå§‹åˆ’åˆ†ä¸ºå•èŠ‚ç‚¹ç¤¾åŒºï¼‰
    ğ“Ÿáµ£: Partition[T] = Partition.singleton_partition(G, Keys.WEIGHT)

    # éå†æ‰€æœ‰ç¤¾åŒº
    for C in ğ“Ÿ:
        # ç»†åŒ–å½“å‰ç¤¾åŒº
        ğ“Ÿáµ£ = merge_nodes_subset(G, ğ“Ÿáµ£, ğ“—, Î¸, Î³, C)

    return ğ“Ÿáµ£



def merge_nodes_subset(G: Graph, ğ“Ÿ: Partition[T], ğ“—: QualityFunction[T], Î¸: float, Î³: float, S: Set[T]) -> Partition[T]:
    """å°†å­é›† S ä¸­çš„èŠ‚ç‚¹åˆå¹¶ä¸ºä¸€ä¸ªæˆ–å¤šä¸ªé›†åˆï¼Œä»¥ç»†åŒ–åˆ’åˆ† ğ“Ÿã€‚"""
    
    # è®¡ç®—å­é›† S çš„èŠ‚ç‚¹æ€»æƒé‡
    size_s = node_total(G, S)

    # é€‰æ‹©åˆ‡å‰²ä»£ä»·è¾ƒé«˜çš„èŠ‚ç‚¹é›†åˆ R
    R = {
        v for v in S
          if nx.cut_size(G, [v], S - {v}, weight=Keys.WEIGHT) >= Î³ * node_total(G, v) * (size_s - node_total(G, v))
    }  # fmt: skip

    for v in R:
        # å¦‚æœ v æ˜¯å•èŠ‚ç‚¹ç¤¾åŒºï¼Œå³å°šæœªè¢«åˆå¹¶çš„èŠ‚ç‚¹
        if len(ğ“Ÿ.node_community(v)) == 1:
            # åªè€ƒè™‘è¿æ¥è‰¯å¥½çš„ç¤¾åŒº
            ğ“£ = freeze([
                C for C in ğ“Ÿ
                  if C <= S and nx.cut_size(G, C, S - C, weight=Keys.WEIGHT) >= Î³ * float(node_total(G, C) * (size_s - node_total(G, C)))
            ])  # fmt: skip

            # éšæœºé€‰æ‹©ä¸€ä¸ªç¤¾åŒºå°† v æ”¾å…¥
            # ä½¿ç”¨ Python çš„ random.choices è¿›è¡ŒåŠ æƒéšæœºé€‰æ‹©

            # åˆ—å‡º ğ“£ ä¸­çš„ç¤¾åŒºä»¥åŠå°† v ç§»åŠ¨åˆ°è¯¥ç¤¾åŒºçš„è´¨é‡å‡½æ•°æå‡ï¼ˆğ›¥ğ“—ï¼‰
            # åªè€ƒè™‘ç§»åŠ¨ v åˆ°è´¨é‡å‡½æ•°ä¸å˜æˆ–æå‡çš„ç¤¾åŒº
            communities = [(C, ğ›¥ğ“—) for (C, ğ›¥ğ“—) in ((C, ğ“—.delta(ğ“Ÿ, v, C)) for C in ğ“£) if ğ›¥ğ“— >= 0]
            # æ ¹æ® ğ›¥ğ“— å€¼è®¡ç®—éšæœºé€‰æ‹©çš„æƒé‡
            weights = [exp(ğ›¥ğ“— / Î¸) for (C, ğ›¥ğ“—) in communities]

            # æœ€ç»ˆé€‰æ‹©æ–°ç¤¾åŒº
            # ä½¿ç”¨ [0][0] æå–ç¤¾åŒºï¼Œå› ä¸º choices è¿”å›çš„æ˜¯åŒ…å«å•ä¸ª (C, ğ›¥ğ“—) å…ƒç»„çš„åˆ—è¡¨
            Câ‚™ = choices(communities, weights=weights, k=1)[0][0]

            # å°† v ç§»åŠ¨åˆ°é€‰ä¸­çš„ç¤¾åŒº
            ğ“Ÿ.move_node(v, Câ‚™)

    return ğ“Ÿ



def mutual_info(partition1: Partition[T], partition2: Partition[T]) -> float:
    """
    Calculate the mutual information between two partitions using scikit-learn's adjusted_mutual_info_score.
    
    Parameters
    ----------
    partition1 : Partition[T]
        The first partition of nodes into communities.
    partition2 : Partition[T]
        The second partition of nodes into communities.
    
    Returns
    -------
    float
        The adjusted mutual information score between the two partitions.
    """
    # è·å–æ¯ä¸ªèŠ‚ç‚¹å¯¹åº”çš„ç¤¾åŒºæ ‡ç­¾
    labels1 = []
    labels2 = []
    
    # å°†æ¯ä¸ªèŠ‚ç‚¹æ˜ å°„åˆ°å…¶å¯¹åº”çš„ç¤¾åŒºæ ‡ç­¾
    node_to_label1 = {node: i for i, community in enumerate(partition1.communities) for node in community}
    node_to_label2 = {node: i for i, community in enumerate(partition2.communities) for node in community}
    
    # å¯¹æ¯ä¸ªèŠ‚ç‚¹çš„æ ‡ç­¾è¿›è¡Œæ’åºï¼Œä½¿å¾—å®ƒä»¬æŒ‰ç…§ç›¸åŒçš„é¡ºåºè¿›è¡Œæ¯”è¾ƒ
    for node in partition1.G.nodes():
        labels1.append(node_to_label1[node])
        labels2.append(node_to_label2[node])
    # ä½¿ç”¨ scikit-learn è®¡ç®—è°ƒæ•´åçš„äº’ä¿¡æ¯åˆ†æ•°
    return adjusted_mutual_info_score(labels1, labels2)


def multi_head_leiden_with_mutual_info(
    G: Graph, ğ“—: QualityFunction[T], num_heads: int, Î»: float, Î¸: float = 0.3, Î³: float = 0.05, weight: Union[str, None] = None
) -> list[Partition[T]]:
    """
    ä½¿ç”¨å¤šå¤´æœºåˆ¶å’Œäº’ä¿¡æ¯æ­£åˆ™åŒ–è¿›è¡ŒLeidenç®—æ³•çš„ç¤¾åŒºå‘ç°ã€‚

    å‚æ•°
    ----------
    G : Graph
        è¦å¤„ç†çš„å›¾/ç½‘ç»œã€‚
    ğ“— : QualityFunction[T]
        ä¼˜åŒ–çš„è´¨é‡å‡½æ•°ã€‚
    num_heads: int
        ç”Ÿæˆä¸åŒç¤¾åŒºåˆ’åˆ†çš„å¤´çš„æ•°é‡ã€‚
    Î» : float
        äº’ä¿¡æ¯æ­£åˆ™åŒ–åœ¨æ€»æŸå¤±ä¸­çš„æƒé‡ã€‚
    Î¸ : float, å¯é€‰
        Leidenç®—æ³•çš„Î¸å‚æ•°ï¼Œé»˜è®¤ä¸º0.3ã€‚
    Î³ : float, å¯é€‰
        Leidenç®—æ³•çš„Î³å‚æ•°ï¼Œé»˜è®¤ä¸º0.05ã€‚
    weight: str | None
        å›¾ä¸­è¾¹çš„æƒé‡å±æ€§ï¼Œé»˜è®¤ä¸ºNoneã€‚

    è¿”å›
    -------
    list[Partition[T]]
        åº”ç”¨äº†äº’ä¿¡æ¯æ­£åˆ™åŒ–çš„ä¸åŒå¤´ç”Ÿæˆçš„ç¤¾åŒºåˆ’åˆ†åˆ—è¡¨ã€‚
    """
    partitions = []
    for i in range(num_heads):
        # ä¼ é€’ä¹‹å‰ç”Ÿæˆçš„å¤´ä½œä¸º `other_partitions`
        other_partitions = partitions[:i]  # æ¯ä¸ªå¤´ä¼ å…¥ä¹‹å‰ç”Ÿæˆçš„å¤´
        
        # è°ƒç”¨Leidenç®—æ³•ï¼ŒåŒæ—¶å¼•å…¥äº’ä¿¡æ¯æ­£åˆ™åŒ–
        ğ“Ÿâ‚š = None
        G_current = preprocess_graph(G, weight)

        if len(partitions) > 0:
            ğ“Ÿ = Partition.from_partition(G_current, partitions[i-1], Keys.WEIGHT)
        else:
            ğ“Ÿ = Partition.singleton_partition(G_current, Keys.WEIGHT)

        while True:
            # è¿›è¡Œå±€éƒ¨èŠ‚ç‚¹ç§»åŠ¨ï¼Œä¼ å…¥å…¶ä»–å¤´çš„ç¤¾åŒºåˆ’åˆ†å’Œæ­£åˆ™åŒ–å‚æ•°Î»
            ğ“Ÿ = move_nodes_fast(G_current, ğ“Ÿ, ğ“—, other_partitions=other_partitions, Î»=Î»)

            # æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶ï¼šè‹¥ç¤¾åŒºä»…ç”±å•ä¸ªèŠ‚ç‚¹ç»„æˆæˆ–åˆ’åˆ†ç»“æœæ”¶æ•›
            if len(ğ“Ÿ) == G_current.order() or ğ“Ÿ == ğ“Ÿâ‚š:
                partitions.append(ğ“Ÿ.flatten())
                break

            ğ“Ÿâ‚š = ğ“Ÿ

            # ä½¿ç”¨Î¸å’ŒÎ³å‚æ•°å¯¹å±€éƒ¨åˆ’åˆ†è¿›è¡Œç»†åŒ–
            ğ“Ÿáµ£ = refine_partition(G_current, ğ“Ÿ, ğ“—, Î¸, Î³)

            # åˆ›å»ºåŸºäºå½“å‰åˆ’åˆ†çš„èšåˆå›¾
            G_current = ğ“Ÿáµ£.aggregate_graph()

            # å°†åŸå§‹ç¤¾åŒºåˆ’åˆ†æ˜ å°„åˆ°èšåˆå›¾
            partitions_dict: dict[int, set[T]] = {id: set() for id in range(len(ğ“Ÿ))}
            for v_agg, nodes in G_current.nodes(data=Keys.NODES):
                community_id = ğ“Ÿ._node_part[next(iter(nodes))]
                partitions_dict[community_id] = partitions_dict[community_id].union({v_agg})

            # å°†åˆ’åˆ†ç»“æœè½¬æ¢ä¸ºåˆ—è¡¨å½¢å¼
            partitions_l: list[set[T]] = list(partitions_dict.values())
            ğ“Ÿ = Partition.from_partition(G_current, partitions_l, Keys.WEIGHT)

    return partitions

