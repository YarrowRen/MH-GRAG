{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/boyuren/Documents/multi_head_graph_rag/MH-GRAG-V1/src/gnn_clustering\n",
      "/Users/boyuren/Documents/multi_head_graph_rag/MH-GRAG-V1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir('/Users/boyuren/Documents/multi_head_graph_rag/MH-GRAG-V1')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 1.7670\n",
      "Epoch 100, Loss: 1.7559\n",
      "Epoch 150, Loss: 1.7511\n",
      "Epoch 200, Loss: 1.7490\n",
      "Epoch 250, Loss: 1.7478\n",
      "Epoch 300, Loss: 1.7470\n",
      "Epoch 350, Loss: 1.7465\n",
      "Epoch 400, Loss: 1.7460\n",
      "Epoch 450, Loss: 1.7457\n",
      "Epoch 500, Loss: 1.7454\n",
      "Epoch 550, Loss: 1.7451\n",
      "Epoch 600, Loss: 1.7449\n",
      "Epoch 650, Loss: 1.7447\n",
      "Epoch 700, Loss: 1.7446\n",
      "Epoch 750, Loss: 1.7445\n",
      "Epoch 800, Loss: 1.7444\n",
      "Epoch 850, Loss: 1.7443\n",
      "Epoch 900, Loss: 1.7442\n",
      "Epoch 950, Loss: 1.7442\n",
      "Epoch 1000, Loss: 1.7441\n",
      "Leiden 算法的模块度: 0.8213\n",
      "Leiden 算法得到的簇数: 109\n",
      "未训练模型（初始嵌入）的 KMeans 聚类模块度: 0.2946\n",
      "KMeans 聚类的模块度: 0.7055\n",
      "随机聚类的模块度: 0.0061\n"
     ]
    }
   ],
   "source": [
    "from src.gnn_clustering.data_loader import load_data\n",
    "from src.gnn_clustering.model import get_model\n",
    "from src.gnn_clustering.loss_functions import modularity_loss\n",
    "from src.gnn_clustering.train import train_model\n",
    "from src.gnn_clustering.evaluate import (\n",
    "    get_embeddings,\n",
    "    kmeans_clustering,\n",
    "    leiden_clustering,\n",
    "    random_clustering,\n",
    "    compute_modularity,\n",
    "    format_communities\n",
    ")\n",
    "from src.gnn_clustering.utils import get_device, get_dense_adj\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 设置设备\n",
    "device = get_device()\n",
    "\n",
    "# 数据加载\n",
    "data = load_data()\n",
    "data = data.to(device)\n",
    "\n",
    "# 使用Leiden算法进行聚类，获取簇数\n",
    "communities_leiden, modularity_leiden = leiden_clustering(data)\n",
    "num_clusters_leiden = len(communities_leiden)\n",
    "\n",
    "# 获取模型\n",
    "model = get_model(data, device=device)\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 获取密集邻接矩阵\n",
    "adj = get_dense_adj(data.edge_index, device=device)\n",
    "\n",
    "# 初始评估\n",
    "initial_embeddings = get_embeddings(model, data, device=device)\n",
    "clusters_kmeans_initial = kmeans_clustering(initial_embeddings, n_clusters=7)\n",
    "communities_kmeans_initial = format_communities(clusters_kmeans_initial, n_clusters=7)\n",
    "modularity_kmeans_initial = compute_modularity(data, communities_kmeans_initial)\n",
    "\n",
    "# 模型训练\n",
    "model = train_model(model, data, adj, modularity_loss, optimizer)\n",
    "\n",
    "# 获取训练后的嵌入\n",
    "embeddings = get_embeddings(model, data, device=device)\n",
    "\n",
    "# KMeans 聚类评估\n",
    "clusters_kmeans = kmeans_clustering(embeddings, n_clusters=7)\n",
    "communities_kmeans = format_communities(clusters_kmeans, n_clusters=7)\n",
    "modularity_kmeans = compute_modularity(data, communities_kmeans)\n",
    "\n",
    "# # Leiden 算法评估\n",
    "# communities_leiden, modularity_leiden = leiden_clustering(data)\n",
    "# print(f'Leiden 算法的模块度: {modularity_leiden:.4f}')\n",
    "\n",
    "# 随机聚类评估\n",
    "communities_random = random_clustering(data.num_nodes, n_clusters=7)\n",
    "modularity_random = compute_modularity(data, communities_random)\n",
    "print(f'Leiden 算法的模块度: {modularity_leiden:.4f}')\n",
    "print(f'Leiden 算法得到的簇数: {num_clusters_leiden}')\n",
    "print(f'未训练模型（初始嵌入）的 KMeans 聚类模块度: {modularity_kmeans_initial:.4f}')\n",
    "print(f'KMeans 聚类的模块度: {modularity_kmeans:.4f}')\n",
    "print(f'随机聚类的模块度: {modularity_random:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 7.3737\n",
      "Epoch 20, Loss: 5.4109\n",
      "Epoch 40, Loss: 5.3432\n",
      "Epoch 60, Loss: 5.3220\n",
      "Epoch 80, Loss: 5.3101\n",
      "Epoch 100, Loss: 5.3021\n",
      "Epoch 120, Loss: 5.2962\n",
      "Epoch 140, Loss: 5.2916\n",
      "Epoch 160, Loss: 5.2878\n",
      "Epoch 180, Loss: 5.2848\n",
      "Epoch 200, Loss: 5.2823\n",
      "头 0 的模块度: 0.7003\n",
      "头 1 的模块度: 0.6706\n",
      "头 2 的模块度: 0.7265\n",
      "头 0 和头 1 之间的调整互信息: 0.2842\n",
      "头 0 和头 2 之间的调整互信息: 0.3700\n",
      "头 1 和头 2 之间的调整互信息: 0.3118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.nn import GCNConv\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from src.gnn_clustering.model import get_multi_head_model\n",
    "from src.gnn_clustering.data_loader import load_data\n",
    "from src.gnn_clustering.utils import get_device, get_dense_adj\n",
    "from src.gnn_clustering.train import train_model_multi_head\n",
    "from src.gnn_clustering.evaluate import (\n",
    "    get_embeddings_list,\n",
    "    kmeans_clustering,\n",
    "    leiden_clustering,\n",
    "    compute_modularity,\n",
    "    format_communities\n",
    ")\n",
    "# 设置设备\n",
    "device = get_device()\n",
    "\n",
    "# 数据加载\n",
    "data = load_data()\n",
    "data = data.to(device)\n",
    "\n",
    "# 使用Leiden算法进行聚类，获取簇数\n",
    "communities_leiden, modularity_leiden = leiden_clustering(data)\n",
    "num_clusters_leiden = len(communities_leiden)\n",
    "\n",
    "num_heads = 3  # 设置头的数量\n",
    "model = get_multi_head_model(data=data, device= device, num_heads=num_heads)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 获取密集邻接矩阵\n",
    "adj = get_dense_adj(data.edge_index, device=device)\n",
    "\n",
    "# 模型训练\n",
    "model = train_model_multi_head(model, data, adj, optimizer, num_heads)\n",
    "\n",
    "embeddings_list = get_embeddings_list(model,data,device)\n",
    "\n",
    "G_nx = to_networkx(data, to_undirected=True)\n",
    "\n",
    "for idx, embeddings in enumerate(embeddings_list):\n",
    "    # KMeans 聚类评估\n",
    "    clusters_kmeans = kmeans_clustering(embeddings, n_clusters=7)\n",
    "    communities_kmeans = format_communities(clusters_kmeans, n_clusters=7)\n",
    "    modularity_kmeans = compute_modularity(data, communities_kmeans)\n",
    "    print(f'头 {idx} 的模块度: {modularity_kmeans:.4f}')\n",
    "\n",
    "# 计算头之间的互信息\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "for i in range(num_heads):\n",
    "    for j in range(i + 1, num_heads):\n",
    "        clusters_i = KMeans(n_clusters=7, random_state=0).fit_predict(embeddings_list[i].cpu().numpy())\n",
    "        clusters_j = KMeans(n_clusters=7, random_state=0).fit_predict(embeddings_list[j].cpu().numpy())\n",
    "        mi = adjusted_mutual_info_score(clusters_i, clusters_j)\n",
    "        print(f'头 {i} 和头 {j} 之间的调整互信息: {mi:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boyuren/Documents/multi_head_graph_rag/MH-GRAG-V1/src/gnn_clustering/data_loader.py:78: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:264.)\n",
      "  edge_index = torch.tensor([source_indices, target_indices], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 0.2406\n",
      "Epoch 100, Loss: 0.2252\n",
      "Epoch 150, Loss: 0.2189\n",
      "Epoch 200, Loss: 0.2156\n",
      "Epoch 250, Loss: 0.2138\n",
      "Epoch 300, Loss: 0.2124\n",
      "Epoch 350, Loss: 0.2114\n",
      "Epoch 400, Loss: 0.2109\n",
      "Epoch 450, Loss: 0.2107\n",
      "Epoch 500, Loss: 0.2106\n",
      "Epoch 550, Loss: 0.2105\n",
      "Epoch 600, Loss: 0.2105\n",
      "Epoch 650, Loss: 0.2104\n",
      "Epoch 700, Loss: 0.2104\n",
      "Epoch 750, Loss: 0.2103\n",
      "Epoch 800, Loss: 0.2103\n",
      "Epoch 850, Loss: 0.2101\n",
      "Epoch 900, Loss: 0.2100\n",
      "Epoch 950, Loss: 0.2097\n",
      "Epoch 1000, Loss: 0.2096\n",
      "Leiden 算法的模块度: 0.5381\n",
      "Leiden 算法得到的簇数: 42\n",
      "未训练模型（初始嵌入）的 KMeans 聚类模块度: 0.2129\n",
      "KMeans 聚类的模块度: 0.4834\n",
      "随机聚类的模块度: 0.0046\n"
     ]
    }
   ],
   "source": [
    "# from src.gnn_clustering.data_loader import load_random_data\n",
    "# from src.gnn_clustering.model import get_model\n",
    "# from src.gnn_clustering.loss_functions import modularity_loss\n",
    "# from src.gnn_clustering.train import train_model\n",
    "# from src.gnn_clustering.evaluate import (\n",
    "#     get_embeddings,\n",
    "#     kmeans_clustering,\n",
    "#     leiden_clustering,\n",
    "#     random_clustering,\n",
    "#     compute_modularity,\n",
    "#     format_communities\n",
    "# )\n",
    "# from src.gnn_clustering.utils import get_device, get_dense_adj\n",
    "# import torch\n",
    "# import numpy as np\n",
    "\n",
    "# # 设置设备\n",
    "# device = get_device()\n",
    "\n",
    "# # 数据加载\n",
    "# data = load_random_data(1024,2048)\n",
    "# data = data.to(device)\n",
    "\n",
    "# # 使用Leiden算法进行聚类，获取簇数\n",
    "# communities_leiden, modularity_leiden = leiden_clustering(data)\n",
    "# num_clusters_leiden = len(communities_leiden)\n",
    "\n",
    "# # 获取模型\n",
    "# model = get_model(data, device=device)\n",
    "\n",
    "# # 定义优化器\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# # 获取密集邻接矩阵\n",
    "# adj = get_dense_adj(data.edge_index, device=device)\n",
    "\n",
    "# # 初始评估\n",
    "# initial_embeddings = get_embeddings(model, data, device=device)\n",
    "# clusters_kmeans_initial = kmeans_clustering(initial_embeddings, n_clusters=7)\n",
    "# communities_kmeans_initial = format_communities(clusters_kmeans_initial, n_clusters=7)\n",
    "# modularity_kmeans_initial = compute_modularity(data, communities_kmeans_initial)\n",
    "\n",
    "# # 模型训练\n",
    "# model = train_model(model, data, adj, modularity_loss, optimizer)\n",
    "\n",
    "# # 获取训练后的嵌入\n",
    "# embeddings = get_embeddings(model, data, device=device)\n",
    "\n",
    "# # KMeans 聚类评估\n",
    "# clusters_kmeans = kmeans_clustering(embeddings, n_clusters=7)\n",
    "# communities_kmeans = format_communities(clusters_kmeans, n_clusters=7)\n",
    "# modularity_kmeans = compute_modularity(data, communities_kmeans)\n",
    "\n",
    "# # # Leiden 算法评估\n",
    "# # communities_leiden, modularity_leiden = leiden_clustering(data)\n",
    "# # print(f'Leiden 算法的模块度: {modularity_leiden:.4f}')\n",
    "\n",
    "# # 随机聚类评估\n",
    "# communities_random = random_clustering(data.num_nodes, n_clusters=7)\n",
    "# modularity_random = compute_modularity(data, communities_random)\n",
    "# print(f'Leiden 算法的模块度: {modularity_leiden:.4f}')\n",
    "# print(f'Leiden 算法得到的簇数: {num_clusters_leiden}')\n",
    "# print(f'未训练模型（初始嵌入）的 KMeans 聚类模块度: {modularity_kmeans_initial:.4f}')\n",
    "# print(f'KMeans 聚类的模块度: {modularity_kmeans:.4f}')\n",
    "# print(f'随机聚类的模块度: {modularity_random:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.1456\n",
      "Epoch 20, Loss: 0.3552\n",
      "Epoch 40, Loss: 0.2841\n",
      "Epoch 60, Loss: 0.2553\n",
      "Epoch 80, Loss: 0.2390\n",
      "Epoch 100, Loss: 0.2285\n",
      "Epoch 120, Loss: 0.2214\n",
      "Epoch 140, Loss: 0.2162\n",
      "Epoch 160, Loss: 0.2121\n",
      "Epoch 180, Loss: 0.2086\n",
      "Epoch 200, Loss: 0.2057\n",
      "Leiden 算法的模块度: 0.7997\n",
      "Leiden 算法得到的簇数: 199\n",
      "未训练模型（初始嵌入）的 KMeans 聚类模块度: 0.3282\n",
      "头 0 的模块度: 0.6775\n",
      "头 1 的模块度: 0.7060\n",
      "头 2 的模块度: 0.6686\n",
      "头 0 和头 1 之间的调整互信息: 0.2152\n",
      "头 0 和头 2 之间的调整互信息: 0.0936\n",
      "头 1 和头 2 之间的调整互信息: 0.1237\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.nn import GCNConv\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from src.gnn_clustering.model import get_multi_head_model, get_model\n",
    "from src.gnn_clustering.data_loader import load_random_data\n",
    "from src.gnn_clustering.utils import get_device, get_dense_adj\n",
    "from src.gnn_clustering.train import train_model_multi_head\n",
    "from src.gnn_clustering.evaluate import (\n",
    "    get_embeddings_list,\n",
    "    kmeans_clustering,\n",
    "    leiden_clustering,\n",
    "    compute_modularity,\n",
    "    format_communities,\n",
    "    random_clustering\n",
    ")\n",
    "# 设置设备\n",
    "device = get_device()\n",
    "\n",
    "# 数据加载\n",
    "data = load_random_data(1024,1024)\n",
    "data = data.to(device)\n",
    "\n",
    "# 使用Leiden算法进行聚类，获取簇数\n",
    "communities_leiden, modularity_leiden = leiden_clustering(data)\n",
    "num_clusters_leiden = len(communities_leiden)\n",
    "\n",
    "num_heads = 3  # 设置头的数量\n",
    "model = get_multi_head_model(data=data, device= device, num_heads=num_heads)\n",
    "single_head_model = get_model(data, device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 获取密集邻接矩阵\n",
    "adj = get_dense_adj(data.edge_index, device=device)\n",
    "\n",
    "# 初始评估\n",
    "initial_embeddings = get_embeddings(single_head_model, data, device=device)\n",
    "clusters_kmeans_initial = kmeans_clustering(initial_embeddings, n_clusters=7)\n",
    "communities_kmeans_initial = format_communities(clusters_kmeans_initial, n_clusters=7)\n",
    "modularity_kmeans_initial = compute_modularity(data, communities_kmeans_initial)\n",
    "# # 随机聚类评估\n",
    "communities_random = random_clustering(data.num_nodes, n_clusters=7)\n",
    "modularity_random = compute_modularity(data, communities_random)\n",
    "\n",
    "# 模型训练\n",
    "model = train_model_multi_head(model, data, adj, optimizer, num_heads)\n",
    "\n",
    "embeddings_list = get_embeddings_list(model,data,device)\n",
    "\n",
    "G_nx = to_networkx(data, to_undirected=True)\n",
    "\n",
    "print(f'Leiden 算法的模块度: {modularity_leiden:.4f}')\n",
    "print(f'Leiden 算法得到的簇数: {num_clusters_leiden}')\n",
    "print(f'未训练模型（初始嵌入）的 KMeans 聚类模块度: {modularity_kmeans_initial:.4f}')\n",
    "print(f'随机聚类的模块度: {modularity_random:.4f}')\n",
    "\n",
    "for idx, embeddings in enumerate(embeddings_list):\n",
    "    # KMeans 聚类评估\n",
    "    clusters_kmeans = kmeans_clustering(embeddings, n_clusters=7)\n",
    "    communities_kmeans = format_communities(clusters_kmeans, n_clusters=7)\n",
    "    modularity_kmeans = compute_modularity(data, communities_kmeans)\n",
    "    print(f'头 {idx} 的模块度: {modularity_kmeans:.4f}')\n",
    "\n",
    "# 计算头之间的互信息\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "for i in range(num_heads):\n",
    "    for j in range(i + 1, num_heads):\n",
    "        clusters_i = KMeans(n_clusters=7, random_state=0).fit_predict(embeddings_list[i].cpu().numpy())\n",
    "        clusters_j = KMeans(n_clusters=7, random_state=0).fit_predict(embeddings_list[j].cpu().numpy())\n",
    "        mi = adjusted_mutual_info_score(clusters_i, clusters_j)\n",
    "        print(f'头 {i} 和头 {j} 之间的调整互信息: {mi:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
